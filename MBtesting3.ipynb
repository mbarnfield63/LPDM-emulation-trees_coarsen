{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import glob\n",
    "import dask\n",
    "import warnings\n",
    "import cartopy\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/user/work/eh19374/LPDM-emulation-trees_TESTING/\")\n",
    "from trees_emulator.load_data import *\n",
    "from trees_emulator.training import *\n",
    "from trees_emulator.predicting import *\n",
    "from trees_emulator.marco_functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this so loaded functions/packages get automatically updated if you edit\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for a particular site\n",
    "domains = {\"MHD\":\"EUROPE\", \"THD\":\"USA\", \"TAC\":\"EUROPE\", \"RGL\":\"EUROPE\", \"HFD\":\"EUROPE\", \"BSD\":\"EUROPE\", \"GSN\":\"EASTASIA\"}\n",
    "heights = {\"MHD\":\"10magl\", \"THD\":\"10magl\", \"TAC\":\"185magl\", \"RGL\":\"90magl\", \"HFD\":\"100magl\", \"BSD\":\"250magl\", \"GSN\":\"10magl\"} # default heights\n",
    "\n",
    "## for UK/Ireland sites (MHD, TAC, RGL, BSD, HFD)\n",
    "met_datadir = \"/group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*\"\n",
    "extramet_datadir = \"/group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/MHD-10magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/MHD-10magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/MHD-10magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/MHD-10magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/MHD-10magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "site = 'MHD'\n",
    "fp_datadir = f\"/group/chemistry/acrg/LPDM/fp_NAME/EUROPE/{site}-{heights[site]}_UKV_EUROPE_*\"\n",
    "MHD_2016 = LoadData(year=\"2016\", site=site, size=10, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "MHD_2016_coarse2 = LoadData(year=\"2016\", site=site, size=9, coarsen_factor=2, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "MHD_2016_coarse3 = LoadData(year=\"2016\", site=site, size=12, coarsen_factor=3, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "MHD_2016_coarse4 = LoadData(year=\"2016\", site=site, size=17, coarsen_factor=4, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "MHD_2016_coarse5 = LoadData(year=\"2016\", site=site, size=22, coarsen_factor=5, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/TAC-185magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/TAC-185magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/TAC-185magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/TAC-185magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/TAC-185magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "site = 'TAC'\n",
    "fp_datadir = f\"/group/chemistry/acrg/LPDM/fp_NAME/EUROPE/{site}-{heights[site]}_UKV_EUROPE_*\"\n",
    "TAC_2016 = LoadData(year=\"2016\", site=site, size=10, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "TAC_2016_coarse2 = LoadData(year=\"2016\", site=site, size=9, coarsen_factor=2, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "TAC_2016_coarse3 = LoadData(year=\"2016\", site=site, size=12, coarsen_factor=3, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "TAC_2016_coarse4 = LoadData(year=\"2016\", site=site, size=17, coarsen_factor=4, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "TAC_2016_coarse5 = LoadData(year=\"2016\", site=site, size=22, coarsen_factor=5, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/RGL-90magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/RGL-90magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/RGL-90magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/RGL-90magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/RGL-90magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "site = 'RGL'\n",
    "fp_datadir = f\"/group/chemistry/acrg/LPDM/fp_NAME/EUROPE/{site}-{heights[site]}_UKV_EUROPE_*\"\n",
    "RGL_2016 = LoadData(year=\"2016\", site=site, size=10, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "RGL_2016_coarse2 = LoadData(year=\"2016\", site=site, size=9, coarsen_factor=2, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "RGL_2016_coarse3 = LoadData(year=\"2016\", site=site, size=12, coarsen_factor=3, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "RGL_2016_coarse4 = LoadData(year=\"2016\", site=site, size=17, coarsen_factor=4, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "RGL_2016_coarse5 = LoadData(year=\"2016\", site=site, size=22, coarsen_factor=5, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/BSD-250magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/BSD-250magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/BSD-250magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/BSD-250magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/BSD-250magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "site = 'BSD'\n",
    "fp_datadir = f\"/group/chemistry/acrg/LPDM/fp_NAME/EUROPE/{site}-{heights[site]}_UKV_EUROPE_*\"\n",
    "BSD_2016 = LoadData(year=\"2016\", site=site, size=10, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "BSD_2016_coarse2 = LoadData(year=\"2016\", site=site, size=9, coarsen_factor=2, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "BSD_2016_coarse3 = LoadData(year=\"2016\", site=site, size=12, coarsen_factor=3, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "BSD_2016_coarse4 = LoadData(year=\"2016\", site=site, size=17, coarsen_factor=4, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "BSD_2016_coarse5 = LoadData(year=\"2016\", site=site, size=22, coarsen_factor=5, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/HFD-100magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/HFD-100magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/HFD-100magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/HFD-100magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n",
      "Loading Meteorology data from /group/chemistry/acrg/met_archive/NAME/EUROPE_met/EUROPE_Met_10magl_*2016*.nc\n",
      "Loading footprint data from /group/chemistry/acrg/LPDM/fp_NAME/EUROPE/HFD-100magl_UKV_EUROPE_*2016*.nc\n",
      "Cutting data to size\n",
      "Loading extra meteorology from /group/chemistry/acrg/met_archive/NAME/full_extra_vars/EUROPE*2016*.nc and extracting gradients\n",
      "Extracting wind vectors\n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "site = 'HFD'\n",
    "fp_datadir = f\"/group/chemistry/acrg/LPDM/fp_NAME/EUROPE/{site}-{heights[site]}_UKV_EUROPE_*\"\n",
    "HFD_2016 = LoadData(year=\"2016\", site=site, size=10, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "HFD_2016_coarse2 = LoadData(year=\"2016\", site=site, size=9, coarsen_factor=2, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "HFD_2016_coarse3 = LoadData(year=\"2016\", site=site, size=12, coarsen_factor=3, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "HFD_2016_coarse4 = LoadData(year=\"2016\", site=site, size=17, coarsen_factor=4, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)\n",
    "HFD_2016_coarse5 = LoadData(year=\"2016\", site=site, size=22, coarsen_factor=5, verbose=True, met_datadir=met_datadir, fp_datadir=fp_datadir, extramet_datadir=extramet_datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model info: {'site': 'MHD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 9}\n",
      "Trained model info: {'site': 'MHD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 12}\n",
      "Trained model info: {'site': 'MHD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 17}\n",
      "Trained model info: {'site': 'MHD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 22}\n"
     ]
    }
   ],
   "source": [
    "# MHD\n",
    "MHD_2 = import_coarsened_and_train('MHD_1415_coarsened2', MHD_2016_coarse2, [6], 14)\n",
    "MHD_3 = import_coarsened_and_train('MHD_1415_coarsened3', MHD_2016_coarse3, [6], 18)\n",
    "MHD_4 = import_coarsened_and_train('MHD_1415_coarsened4', MHD_2016_coarse4, [6], 22)\n",
    "MHD_5 = import_coarsened_and_train('MHD_1415_coarsened5', MHD_2016_coarse5, [6], 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model info: {'site': 'TAC', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 9}\n",
      "Trained model info: {'site': 'TAC', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 12}\n",
      "Trained model info: {'site': 'TAC', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 17}\n",
      "Trained model info: {'site': 'TAC', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 22}\n"
     ]
    }
   ],
   "source": [
    "# TAC\n",
    "TAC_2 = import_coarsened_and_train('TAC_1415_coarsened2', TAC_2016_coarse2, [6], 14)\n",
    "TAC_3 = import_coarsened_and_train('TAC_1415_coarsened3', TAC_2016_coarse3, [6], 18)\n",
    "TAC_4 = import_coarsened_and_train('TAC_1415_coarsened4', TAC_2016_coarse4, [6], 22)\n",
    "TAC_5 = import_coarsened_and_train('TAC_1415_coarsened5', TAC_2016_coarse5, [6], 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model info: {'site': 'RGL', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 9}\n",
      "Trained model info: {'site': 'RGL', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 12}\n",
      "Trained model info: {'site': 'RGL', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 17}\n",
      "Trained model info: {'site': 'RGL', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 22}\n"
     ]
    }
   ],
   "source": [
    "# RGL\n",
    "RGL_2 = import_coarsened_and_train('RGL_1415_coarsened2', RGL_2016_coarse2, [6], 14)\n",
    "RGL_3 = import_coarsened_and_train('RGL_1415_coarsened3', RGL_2016_coarse3, [6], 18)\n",
    "RGL_4 = import_coarsened_and_train('RGL_1415_coarsened4', RGL_2016_coarse4, [6], 22)\n",
    "RGL_5 = import_coarsened_and_train('RGL_1415_coarsened5', RGL_2016_coarse5, [6], 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model info: {'site': 'BSD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 9}\n",
      "Trained model info: {'site': 'BSD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 12}\n",
      "Trained model info: {'site': 'BSD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 17}\n",
      "Trained model info: {'site': 'BSD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 22}\n"
     ]
    }
   ],
   "source": [
    "# BSD\n",
    "BSD_2 = import_coarsened_and_train('BSD_1415_coarsened2', BSD_2016_coarse2, [6], 14)\n",
    "BSD_3 = import_coarsened_and_train('BSD_1415_coarsened3', BSD_2016_coarse3, [6], 18)\n",
    "BSD_4 = import_coarsened_and_train('BSD_1415_coarsened4', BSD_2016_coarse4, [6], 22)\n",
    "BSD_5 = import_coarsened_and_train('BSD_1415_coarsened5', BSD_2016_coarse5, [6], 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model info: {'site': 'HFD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 9}\n",
      "Trained model info: {'site': 'HFD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 12}\n",
      "Trained model info: {'site': 'HFD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 17}\n",
      "Trained model info: {'site': 'HFD', 'training data': '201[4-5]', 'sampling frequency': 2, 'size': 22}\n"
     ]
    }
   ],
   "source": [
    "# HFD\n",
    "HFD_2 = import_coarsened_and_train('HFD_1415_coarsened2', HFD_2016_coarse2, [6], 14)\n",
    "HFD_3 = import_coarsened_and_train('HFD_1415_coarsened3', HFD_2016_coarse3, [6], 18)\n",
    "HFD_4 = import_coarsened_and_train('HFD_1415_coarsened4', HFD_2016_coarse4, [6], 22)\n",
    "HFD_5 = import_coarsened_and_train('HFD_1415_coarsened5', HFD_2016_coarse5, [6], 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uncoarsen(dataset, dataset_coarsened, dataOG, coarsen_factor, show_plot=False, date=0):\n",
    "    data = dataset.predictions\n",
    "    data_fp_coarse = dataset_coarsened.fp_data\n",
    "\n",
    "    data = data.reshape(len(data), dataset.size, dataset.size)\n",
    "    data_fp_coarse = data_fp_coarse.reshape(len(data_fp_coarse), dataset.size, dataset.size)\n",
    "    data_fp_coarse = data_fp_coarse[dataset.jump:-3]\n",
    "    \n",
    "    array = xr.DataArray(data, coords=[('time', dataset.data.met.time.values[dataset.jump:-3]),\n",
    "                                        ('lat', dataset.data.fp_lats),\n",
    "                                        ('lon', dataset.data.fp_lons)])\n",
    "    \n",
    "    fp = xr.DataArray(data_fp_coarse, coords=[('time', dataset.data.met.time.values[dataset.jump:-3]),\n",
    "                                            ('lat', dataset.data.fp_lats),\n",
    "                                            ('lon', dataset.data.fp_lons)])\n",
    "    \n",
    "    new_lats = dataOG.fp_data_full.lat\n",
    "    new_lons = dataOG.fp_data_full.lon\n",
    "    \n",
    "    array = array.interp(lat=new_lats, lon=new_lons, method='nearest')\n",
    "    array = xr.where((array > 0) & ~np.isnan(array), array/coarsen_factor, array)\n",
    "\n",
    "    fp = fp.interp(lat=new_lats, lon=new_lons, method='nearest')\n",
    "    fp = xr.where((fp > 0) & ~np.isnan(fp), fp/coarsen_factor, fp)\n",
    "\n",
    "    if show_plot==True:\n",
    "        plot_xarray(array, date, dataset.data.site, coarsen_factor)\n",
    "\n",
    "    return array, fp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHD\n",
    "MHD_2_uncoarsened_predictions, MHD_2_uncoarsened_fp_data = Uncoarsen(MHD_2, MHD_2016_coarse2, MHD_2016, 2)\n",
    "MHD_3_uncoarsened_predictions, MHD_3_uncoarsened_fp_data = Uncoarsen(MHD_3, MHD_2016_coarse3, MHD_2016, 3)\n",
    "MHD_4_uncoarsened_predictions, MHD_4_uncoarsened_fp_data = Uncoarsen(MHD_4, MHD_2016_coarse4, MHD_2016, 4)\n",
    "MHD_5_uncoarsened_predictions, MHD_5_uncoarsened_fp_data = Uncoarsen(MHD_5, MHD_2016_coarse5, MHD_2016, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAC\n",
    "TAC_2_uncoarsened_predictions, TAC_2_uncoarsened_fp_data = Uncoarsen(TAC_2, TAC_2016_coarse2, TAC_2016, 2)\n",
    "TAC_3_uncoarsened_predictions, TAC_3_uncoarsened_fp_data = Uncoarsen(TAC_3, TAC_2016_coarse3, TAC_2016, 3)\n",
    "TAC_4_uncoarsened_predictions, TAC_4_uncoarsened_fp_data = Uncoarsen(TAC_4, TAC_2016_coarse4, TAC_2016, 4)\n",
    "TAC_5_uncoarsened_predictions, TAC_5_uncoarsened_fp_data = Uncoarsen(TAC_5, TAC_2016_coarse5, TAC_2016, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGL\n",
    "RGL_2_uncoarsened_predictions, RGL_2_uncoarsened_fp_data = Uncoarsen(RGL_2, RGL_2016_coarse2, RGL_2016, 2)\n",
    "RGL_3_uncoarsened_predictions, RGL_3_uncoarsened_fp_data = Uncoarsen(RGL_3, RGL_2016_coarse3, RGL_2016, 3)\n",
    "RGL_4_uncoarsened_predictions, RGL_4_uncoarsened_fp_data = Uncoarsen(RGL_4, RGL_2016_coarse4, RGL_2016, 4)\n",
    "RGL_5_uncoarsened_predictions, RGL_5_uncoarsened_fp_data = Uncoarsen(RGL_5, RGL_2016_coarse5, RGL_2016, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# BSD\n",
    "BSD_2_uncoarsened_predictions, BSD_2_uncoarsened_fp_data = Uncoarsen(BSD_2, BSD_2016_coarse2, BSD_2016, 2)\n",
    "BSD_3_uncoarsened_predictions, BSD_3_uncoarsened_fp_data = Uncoarsen(BSD_3, BSD_2016_coarse3, BSD_2016, 3)\n",
    "BSD_4_uncoarsened_predictions, BSD_4_uncoarsened_fp_data = Uncoarsen(BSD_4, BSD_2016_coarse4, BSD_2016, 4)\n",
    "BSD_5_uncoarsened_predictions, BSD_5_uncoarsened_fp_data = Uncoarsen(BSD_5, BSD_2016_coarse5, BSD_2016, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HFD\n",
    "HFD_2_uncoarsened_predictions, HFD_2_uncoarsened_fp_data = Uncoarsen(HFD_2, HFD_2016_coarse2, HFD_2016, 2)\n",
    "HFD_3_uncoarsened_predictions, HFD_3_uncoarsened_fp_data = Uncoarsen(HFD_3, HFD_2016_coarse3, HFD_2016, 3)\n",
    "HFD_4_uncoarsened_predictions, HFD_4_uncoarsened_fp_data = Uncoarsen(HFD_4, HFD_2016_coarse4, HFD_2016, 4)\n",
    "HFD_5_uncoarsened_predictions, HFD_5_uncoarsened_fp_data = Uncoarsen(HFD_5, HFD_2016_coarse5, HFD_2016, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all(list_of_xarrays, original_data, return_all=False):\n",
    "    # combine uncoarsened datasets\n",
    "    combined = list_of_xarrays[0]\n",
    "    for x in range(len(list_of_xarrays)-1):\n",
    "        combined = combined.combine_first(list_of_xarrays[x+1])\n",
    "    \n",
    "    combined = xr.where((combined < 0.0005) & ~np.isnan(combined), 0, combined)\n",
    "\n",
    "    # place OG at centre\n",
    "    OG_data = original_data.fp_data.reshape(-1, 10, 10)\n",
    "    OG_data = OG_data[6:-3]\n",
    "\n",
    "    # Find indices in combined that correspond to the indices in OG_data\n",
    "    og_lat_indices = np.searchsorted(combined.lat, original_data.fp_lats)\n",
    "    og_lon_indices = np.searchsorted(combined.lon, original_data.fp_lons)\n",
    "\n",
    "    # Replace values using the indices\n",
    "    combined[:, og_lat_indices, og_lon_indices] = OG_data\n",
    "\n",
    "    # Create copy of OG xarray to use to fill surrounding values\n",
    "    fp_data = np.array(original_data.fp_data_full.fp)\n",
    "    fp_data = np.transpose(fp_data, (2,0,1))[6:-3]\n",
    "    OG_copy = xr.DataArray(fp_data, coords=[('time', np.array(original_data.fp_data_full.time[6:-3])),\n",
    "                                            ('lat', np.array(original_data.fp_data_full.lat)),\n",
    "                                            ('lon', np.array(original_data.fp_data_full.lon))])\n",
    "\n",
    "    final = xr.where(~np.isnan(combined), combined, OG_copy)\n",
    "\n",
    "    if return_all == True: return final, combined, OG_copy\n",
    "    else: return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHD_uncoarsened = [MHD_2_uncoarsened_predictions, \n",
    "                   MHD_3_uncoarsened_predictions, \n",
    "                   MHD_4_uncoarsened_predictions, \n",
    "                   MHD_5_uncoarsened_predictions]\n",
    "\n",
    "MHD_final, MHD_combined, MHD_OG = combine_all(MHD_uncoarsened, MHD_2016, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_xarray(MHD_final, 950, 'MHD', 5)\n",
    "# plt.savefig('plots/MHD_final_mean_threshold_0005.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAC_uncoarsened = [TAC_2_uncoarsened_predictions, \n",
    "                   TAC_3_uncoarsened_predictions, \n",
    "                   TAC_4_uncoarsened_predictions, \n",
    "                   TAC_5_uncoarsened_predictions]\n",
    "\n",
    "TAC_final, TAC_combined, TAC_OG = combine_all(TAC_uncoarsened, TAC_2016, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_xarray(TAC_final, 950, 'TAC', 5)\n",
    "# plt.savefig('plots/TAC_final_mean_threshold_005.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGL_uncoarsened = [RGL_2_uncoarsened_predictions, \n",
    "                   RGL_3_uncoarsened_predictions, \n",
    "                   RGL_4_uncoarsened_predictions, \n",
    "                   RGL_5_uncoarsened_predictions]\n",
    "\n",
    "RGL_final, RGL_combined, RGL_OG = combine_all(RGL_uncoarsened, RGL_2016, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_xarray(RGL_final, 950, 'RGL', 5)\n",
    "# plt.savefig('plots/RGL_final_mean_threshold_none.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSD_uncoarsened = [BSD_2_uncoarsened_predictions, \n",
    "                   BSD_3_uncoarsened_predictions, \n",
    "                   BSD_4_uncoarsened_predictions, \n",
    "                   BSD_5_uncoarsened_predictions]\n",
    "\n",
    "BSD_final, BSD_combined, BSD_OG = combine_all(BSD_uncoarsened, BSD_2016, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_xarray(BSD_final, 950, 'BSD', 5)\n",
    "# plt.savefig('plots/BSD_final_mean_threshold_005.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFD_uncoarsened = [HFD_2_uncoarsened_predictions, \n",
    "                   HFD_3_uncoarsened_predictions, \n",
    "                   HFD_4_uncoarsened_predictions, \n",
    "                   HFD_5_uncoarsened_predictions]\n",
    "\n",
    "HFD_final, HFD_combined, HFD_OG = combine_all(HFD_uncoarsened, HFD_2016, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_xarray(HFD_final, 950, 'HFD', 5)\n",
    "# plt.savefig('plots/HFD_final_mean_threshold_005.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_coarsened_and_OG(coarsened_combined, OG_data):\n",
    "    combined = coarsened_combined.dropna(dim='lat', how='all')\n",
    "    combined = combined.dropna(dim='lon', how='all')\n",
    "    combined_data = combined.data\n",
    "\n",
    "    lat_mask = OG_data.lat.isin(combined.lat.values)\n",
    "    lon_mask = OG_data.lon.isin(combined.lon.values)\n",
    "\n",
    "    filtered_OG = OG_data.where(lat_mask, drop=True).where(lon_mask, drop=True)\n",
    "    filtered_OG_data = filtered_OG.data\n",
    "\n",
    "    return combined_data, filtered_OG_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_array(array, threshold):\n",
    "    # Create a new array of the same shape as the input array\n",
    "    binarized_array = np.zeros_like(array, dtype=np.int)\n",
    "    \n",
    "    # Set values greater than or equal to the threshold to 1\n",
    "    binarized_array[array >= threshold] = 1\n",
    "    \n",
    "    return binarized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_IoU_dice(iou_array, dice_array, site, coarsened_OG=False):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].hist(iou_array, bins=50)\n",
    "    ax[0].set_title(f'{site} IoU\\n(mean = {iou_array.mean():.2f})')\n",
    "\n",
    "    ax[1].hist(dice_array, bins=50)\n",
    "    ax[1].set_title(f'{site} Dice Similarity\\n(mean = {dice_array.mean():.2f})')\n",
    "\n",
    "    if coarsened_OG == True: plt.suptitle('{site} predictions vs coarsened truths')\n",
    "    else: plt.suptitle(f'{site}\\npredictions vs original truths')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHD_5x_data, MHD_OG_data = trim_coarsened_and_OG(MHD_final, MHD_OG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "MHD_binary = binarize_array(MHD_5x_data, threshold).reshape(11130, 8775)\n",
    "MHD_binary_OG = binarize_array(MHD_OG_data, threshold).reshape(11130, 8775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHD_IoU = intersection_over_union(MHD_binary, MHD_binary_OG, zero=0)\n",
    "MHD_dice = dice_similarity(MHD_binary, MHD_binary_OG, zero=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_IoU_dice(MHD_IoU, MHD_dice, 'MHD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
